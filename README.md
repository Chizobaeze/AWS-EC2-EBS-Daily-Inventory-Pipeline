# AWS EC2 & EBS Daily Inventory Pipeline
## ğŸ“Œ Project Overview

The AWS EC2 & EBS Daily Inventory Pipeline is an EC2-hosted Apache Airflow pipeline that collects daily inventory data for EC2 instances and EBS volumes across multiple AWS regions and stores the results in Amazon S3.

The pipeline runs on an AWS EC2 instance using Dockerized Airflow services and is designed to:

Track EC2 and EBS inventory on a daily basis

Identify unused EBS volumes

Maintain historical snapshots for auditing and cost optimization

Demonstrate real-world Airflow deployment on AWS EC2

## ğŸ—ï¸ Architecture Overview

Workflow:

Apache Airflow runs on an EC2 instance

DAG executes a Python task

Boto3 queries EC2 and EBS resources across regions

Pandas structures the extracted data

AWS Wrangler writes Parquet files to Amazon S3

Airflow logs execution and success state

## ğŸ§° Tech Stack
Layer	Technology
Compute	AWS EC2
Orchestration	Apache Airflow
Containerization	Docker & Docker Compose
SDK	Boto3
Processing	Pandas
Storage	Amazon S3
File Format	Parquet
AWS Helper Library	AWS Wrangler


## ğŸ“ Project Structure

```text
ec2_airflow/
â”‚
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ ec2_extract.py
â”‚   â””â”€â”€ ec2_dags.py
â”‚
â”œâ”€â”€ config/
â”œâ”€â”€ logs/
â”œâ”€â”€ plugins/
â”‚
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

